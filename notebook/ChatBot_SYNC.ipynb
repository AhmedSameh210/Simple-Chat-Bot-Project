{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chat Bot Project \n",
        "it is based on NLP and deep learning by using tensor flow made by google to make the model that classify the tag and randomely choose a response based on the user input "
      ],
      "metadata": {
        "id": "9NpYBlA_Q2ir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Json File Generation \n",
        "that contain the dectionary of the tags and to improve the chat bot to answer more questions in different tags we can add more tag or use different approach to build the chat bot as use api "
      ],
      "metadata": {
        "id": "fwpbkKjIRWDA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Sio2ss2LQbN9"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "aDict = {\"intents\": [\n",
        "        {\"tag\": \"greeting\",\n",
        "         \"patterns\": [\"Hi there\", \"How are you\", \"Is anyone there?\",\"Hey\",\"Hola\", \"Hello\", \"Good day\"],\n",
        "         \"responses\": [\"Hello\", \"Good to see you again\", \"Hi there, how can I help?\"],\n",
        "         \"context\": [\"\"]\n",
        "        },\n",
        "        {\"tag\": \"goodbye\",\n",
        "         \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\", \"Nice chatting to you, bye\", \"Till next time\"],\n",
        "         \"responses\": [\"See you!\", \"Have a nice day\", \"Bye! Come back again soon.\"],\n",
        "         \"context\": [\"\"]\n",
        "        },\n",
        "        {\"tag\": \"thanks\",\n",
        "         \"patterns\": [\"Thanks\", \"Thank you\", \"That's helpful\", \"Awesome, thanks\", \"Thanks for helping me\"],\n",
        "         \"responses\": [\"My pleasure\", \"You're Welcome\"],\n",
        "         \"context\": [\"\"]\n",
        "        },\n",
        "        {\"tag\": \"query\",\n",
        "         \"patterns\": [\"What is big bang?\"],\n",
        "         \"responses\": [\"The Big Bang theory is the prevailing cosmological model explaining the existence of the observable universe from the earliest known periods through its subsequent large-scale evolution.\"],\n",
        "         \"context\": [\"\"]\n",
        "        } \n",
        "    ]\n",
        " }\n",
        "jsonString = json.dumps(aDict)\n",
        "jsonFile = open(\"data.json\", \"w\")\n",
        "jsonFile.write(jsonString)\n",
        "jsonFile.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Needed Liberaries "
      ],
      "metadata": {
        "id": "o66klISLR43T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tflearn "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcSSAWFS9Lf9",
        "outputId": "5ae87150-cc89-4596-a208-2f3e32a36570"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tflearn\n",
            "  Downloading tflearn-0.5.0.tar.gz (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from tflearn) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from tflearn) (1.16.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from tflearn) (8.4.0)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127299 sha256=58b98be0e440a6daa2929666e00cbe7a407c1de88d96c1aed467763dc23587f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/d5/f8/9585b4a100c0fd73da204ee785457d67c85e1b9050f009a849\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk \n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "import random\n",
        "import numpy as np \n",
        "import json \n",
        "import pickle \n",
        "import tensorflow as tf \n",
        "import tflearn\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSA5Sw6XSDE3",
        "outputId": "f33a7e5a-2725-404a-f7f6-ebfe2222131c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement the Chat Bot "
      ],
      "metadata": {
        "id": "-ahNoC8hT8yB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/data.json') as intents:\n",
        "  data = json.load(intents)\n",
        "# open the json file and store it in data "
      ],
      "metadata": {
        "id": "f2V3_7svTC8N"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXK9PyOTTW84",
        "outputId": "e7680733-1a65-4fcf-fb27-f627601e0348"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intents': [{'tag': 'greeting',\n",
              "   'patterns': ['Hi there',\n",
              "    'How are you',\n",
              "    'Is anyone there?',\n",
              "    'Hey',\n",
              "    'Hola',\n",
              "    'Hello',\n",
              "    'Good day'],\n",
              "   'responses': ['Hello',\n",
              "    'Good to see you again',\n",
              "    'Hi there, how can I help?'],\n",
              "   'context': ['']},\n",
              "  {'tag': 'goodbye',\n",
              "   'patterns': ['Bye',\n",
              "    'See you later',\n",
              "    'Goodbye',\n",
              "    'Nice chatting to you, bye',\n",
              "    'Till next time'],\n",
              "   'responses': ['See you!', 'Have a nice day', 'Bye! Come back again soon.'],\n",
              "   'context': ['']},\n",
              "  {'tag': 'thanks',\n",
              "   'patterns': ['Thanks',\n",
              "    'Thank you',\n",
              "    \"That's helpful\",\n",
              "    'Awesome, thanks',\n",
              "    'Thanks for helping me'],\n",
              "   'responses': ['My pleasure', \"You're Welcome\"],\n",
              "   'context': ['']},\n",
              "  {'tag': 'query',\n",
              "   'patterns': ['What is big bang?'],\n",
              "   'responses': ['The Big Bang theory is the prevailing cosmological model explaining the existence of the observable universe from the earliest known periods through its subsequent large-scale evolution.'],\n",
              "   'context': ['']}]}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = LancasterStemmer()\n",
        "words = []\n",
        "labels = []\n",
        "x_docs = []\n",
        "y_docs = []\n",
        "# lists to store the data from json  file "
      ],
      "metadata": {
        "id": "HNJEETGfTgWM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for intent in data['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        wrds = nltk.word_tokenize(pattern)\n",
        "        words.extend(wrds)\n",
        "        x_docs.append(wrds)\n",
        "        y_docs.append(intent['tag'])\n",
        "\n",
        "        if intent['tag'] not in labels:\n",
        "            labels.append(intent['tag'])"
      ],
      "metadata": {
        "id": "S_ukby7z9myq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming the words and removing duplicate elements.\n",
        "words = [stemmer.stem(w.lower()) for w in words if w not in \"?\"]\n",
        "words = sorted(list(set(words)))\n",
        "labels = sorted(labels)\n"
      ],
      "metadata": {
        "id": "Q_-A50OP96bK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training = []\n",
        "output = []\n",
        "out_empty = [0 for _ in range(len(labels))]\n",
        "\n",
        "# One hot encoding, Converting the words to numerals\n",
        "for x, doc in enumerate(x_docs):\n",
        "    bag = []\n",
        "    wrds = [stemmer.stem(w) for w in doc]\n",
        "    for w in words:\n",
        "        if w in wrds:\n",
        "            bag.append(1)\n",
        "        else:\n",
        "            bag.append(0)\n",
        "\n",
        "\n",
        "    output_row = out_empty[:]\n",
        "    output_row[labels.index(y_docs[x])] = 1\n",
        "\n",
        "    training.append(bag)\n",
        "    output.append(output_row)\n",
        "\n",
        "\n",
        "training = np.array(training)\n",
        "output = np.array(output)\n",
        "\n",
        "# using a bag of words (from scratch) to make a training features "
      ],
      "metadata": {
        "id": "CWwiDN3x-Iek"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = tflearn.input_data(shape=[None, len(training[0])])\n",
        "net = tflearn.fully_connected(net, 10)\n",
        "net = tflearn.fully_connected(net, 10)\n",
        "net = tflearn.fully_connected(net, 10)\n",
        "net = tflearn.fully_connected(net, len(output[0]), activation='softmax')\n",
        "net = tflearn.regression(net)\n",
        "\n",
        "model = tflearn.DNN(net)\n",
        "model.fit(training, output, n_epoch=500, batch_size=8, show_metric=True)\n",
        "model.save('model.tflearn')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82BiU6eX-xxL",
        "outputId": "c1f3c8e4-dab6-43f2-b862-f66fa6f5061f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Step: 1499  | total loss: \u001b[1m\u001b[32m0.07990\u001b[0m\u001b[0m | time: 0.007s\n",
            "| Adam | epoch: 500 | loss: 0.07990 - acc: 1.0000 -- iter: 16/18\n",
            "Training Step: 1500  | total loss: \u001b[1m\u001b[32m0.08100\u001b[0m\u001b[0m | time: 0.011s\n",
            "| Adam | epoch: 500 | loss: 0.08100 - acc: 1.0000 -- iter: 18/18\n",
            "--\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the Input Function for predict "
      ],
      "metadata": {
        "id": "9TzcvV0F_v9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bag_of_words(s, words):\n",
        "    bag = [0 for _ in range(len(words))]\n",
        "    s_words = nltk.word_tokenize(s)\n",
        "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
        "\n",
        "    for s_word in s_words:\n",
        "        for i, w in enumerate(words):\n",
        "            if w == s_word:\n",
        "                bag[i] = 1\n",
        "\n",
        "    return np.array(bag)\n",
        "# function to convert the input of the user to the bag of word to easly pass to the model for prediction "
      ],
      "metadata": {
        "id": "Jf83S4-e_t89"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_bot():\n",
        "\n",
        "    while True:\n",
        "        inp = input(\"\\n\\nYou : \")\n",
        "        if inp.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "    #Porbability of correct response \n",
        "        results = model.predict([bag_of_words(inp, words)])\n",
        "\n",
        "    # Picking the greatest number from probability\n",
        "        results_index = np.argmax(results)\n",
        "\n",
        "        tag = labels[results_index]\n",
        "\n",
        "        for tg in data['intents']:\n",
        "\n",
        "            if tg['tag'] == tag:\n",
        "                responses = tg['responses']\n",
        "                print(\"\\nBot:\\t\" + random.choice(responses))"
      ],
      "metadata": {
        "id": "SSxYG4ldAzEA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# try the chat bot "
      ],
      "metadata": {
        "id": "IRXEbpOrCFPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_bot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S076Im1NA9qe",
        "outputId": "4cda694b-4c9c-4bc5-8fc8-7e18c11bf504"
      },
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "You : hello\n",
            "\n",
            "Bot:\tHi there, how can I help?\n",
            "\n",
            "\n",
            "You : what is the big bang \n",
            "\n",
            "Bot:\tThe Big Bang theory is the prevailing cosmological model explaining the existence of the observable universe from the earliest known periods through its subsequent large-scale evolution.\n",
            "\n",
            "\n",
            "You : thanks\n",
            "\n",
            "Bot:\tYou're Welcome\n",
            "\n",
            "\n",
            "You : bye\n",
            "\n",
            "Bot:\tBye! Come back again soon.\n",
            "\n",
            "\n",
            "You : exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the future work is to change the approach of the chat bot and use api in addition to make a GUI to be user friendly "
      ],
      "metadata": {
        "id": "p_2ALM24E4X6"
      }
    }
  ]
}